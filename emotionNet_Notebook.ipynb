{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12795,
     "status": "ok",
     "timestamp": 1698738422682,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "cG_GEj9-WMvH",
    "outputId": "14fe9b08-3b00-4f14-a8a9-b057589596fc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7874,
     "status": "ok",
     "timestamp": 1698738430553,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "P2uM_lF3yRQ5",
    "outputId": "a81a7a18-77f3-4066-9b11-a9092fa52193"
   },
   "outputs": [],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXeBLZ7EpiBX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698738438869,
     "user_tz": -660,
     "elapsed": 8317,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torch import nn, onnx\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2tHOzhRWNoR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698738440586,
     "user_tz": -660,
     "elapsed": 1727,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     }
    }
   },
   "outputs": [],
   "source": [
    "### data preprocess\n",
    "\n",
    "# resize image size and set it to tensor for dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# use imagefolder to get all image samples with labels in each class folder\n",
    "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/comp8420/Subset For Assignment SFEW', transform=transform)\n",
    "\n",
    "# Split datasets\n",
    "train_indices = []\n",
    "valid_indices = []\n",
    "test_indices = []\n",
    "for class_index in range(len(dataset.classes)):\n",
    "  class_indices = [i for i, (img, label) in enumerate(dataset.samples) if label == class_index]\n",
    "  train_class_indices, test_class_indices = train_test_split(class_indices, test_size=0.2, random_state=42)\n",
    "  valid_class_indices, test_class_indices = train_test_split(test_class_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "  train_indices.extend(train_class_indices)\n",
    "  valid_indices.extend(valid_class_indices)\n",
    "  test_indices.extend(test_class_indices)\n",
    "\n",
    "# Create subset dataloaders\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "valid_dataset = Subset(dataset, valid_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1698641836565,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "6O5DNyR4mirW",
    "outputId": "fb6469a2-14a1-4b5d-bba4-385d657ffb37"
   },
   "outputs": [],
   "source": [
    "# get the class index to differ each face emotion\n",
    "class_index = dataset.class_to_idx\n",
    "class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYzLSujY8dPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPFNuJKvmjsf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698738440586,
     "user_tz": -660,
     "elapsed": 4,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     }
    }
   },
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "  def __init__(self, kernel_size=7):\n",
    "    super(SpatialAttention, self).__init__()\n",
    "    assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "    padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "    self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Average along channel axis\n",
    "    avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "    # Max along channel axis\n",
    "    max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "    # Stack channel-wise\n",
    "    x = torch.cat([avg_out, max_out], dim=1)\n",
    "    x = self.conv1(x)\n",
    "    return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1698738444676,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "yuMzHEwwmqMZ"
   },
   "outputs": [],
   "source": [
    "class ResNetSA(nn.Module):\n",
    "  def __init__(self, num_classes=7):\n",
    "    super(ResNetSA, self).__init__()\n",
    "    self.resnet = models.resnet18(pretrained=True)\n",
    "    # self.resnet = models.resnet50(pretrained=True)\n",
    "    self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    self.sa = SpatialAttention()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.resnet.conv1(x)\n",
    "    x = self.resnet.bn1(x)\n",
    "    x = self.resnet.relu(x)\n",
    "    x = self.resnet.maxpool(x)\n",
    "\n",
    "    # x = self.sa(x) * x\n",
    "\n",
    "    x = self.resnet.layer1(x)\n",
    "    x = self.sa(x) * x  # Spatial Attention\n",
    "\n",
    "    x = self.resnet.layer2(x)\n",
    "    # x = self.sa(x) * x\n",
    "\n",
    "    x = self.resnet.layer3(x)\n",
    "    # x = self.sa(x) * x\n",
    "\n",
    "    x = self.resnet.layer4(x)\n",
    "    # x = self.sa(x) * x\n",
    "\n",
    "    x = self.resnet.avgpool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.resnet.fc(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7qNNPfSoLMS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ld7i21SZmkM2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eUh-9Stdneyt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698739197688,
     "user_tz": -660,
     "elapsed": 726353,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     }
    },
    "outputId": "7ade1ecf-13d3-4e67-c07b-593699418793"
   },
   "outputs": [],
   "source": [
    "### start to run model\n",
    "\n",
    "# load emotionnet model and set loss and optimizer\n",
    "num_epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNetSA().to(device)\n",
    "# model = models.resnet18(pretrained=True).to(device)\n",
    "# model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "# use tensorboard to record training process\n",
    "writer = SummaryWriter('/content/drive/MyDrive/comp8420/runs_resnet18input')\n",
    "## train\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  # batch size\n",
    "  for images, labels in train_dataloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    # predicts\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "    _, predicts = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicts == labels).sum().item()\n",
    "  # update learning rate\n",
    "  scheduler.step()\n",
    "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, running_loss/len(train_dataloader)))\n",
    "  # write outputs in tensorboard\n",
    "  writer.add_scalar('training loss:', running_loss / len(train_dataloader), epoch)\n",
    "  writer.add_scalar('training accuracy:', 100 * correct / total, epoch)\n",
    "  # weight analysis\n",
    "  for name, param in model.named_parameters():\n",
    "    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
    "\n",
    "  ## validation\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  val_predicts = []\n",
    "  val_labels = []\n",
    "  with torch.no_grad():\n",
    "    for images, labels in valid_dataloader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      outputs = model(images)\n",
    "      _, predicts = torch.max(outputs, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicts == labels).sum().item()\n",
    "\n",
    "      val_predicts.extend(predicts.cpu().numpy())\n",
    "      val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  # write outputs in tensorboard\n",
    "  writer.add_scalar('validation loss:', running_loss / len(train_dataloader), epoch)\n",
    "  writer.add_scalar('validation accuracy:', 100 * correct / total, epoch)\n",
    "\n",
    "# plot the outputs\n",
    "sns.heatmap(confusion_matrix(val_labels,val_predicts), annot=True, fmt='d', cmap='Pastel1')\n",
    "plt.xlabel('Validation Predicts')\n",
    "plt.ylabel('Validation Labels')\n",
    "plt.show()\n",
    "\n",
    "writer.close()\n",
    "# save model\n",
    "# torch.save(model.state_dict(), '/content/drive/MyDrive/comp8420/emotionNet_model.pth')\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device=device)\n",
    "onnx_path = \"/content/drive/MyDrive/comp8420/emotionNet_resnet18input.onnx\"  # The file path to save the ONNX model\n",
    "onnx.export(model, dummy_input, onnx_path)\n",
    "\n",
    "## test\n",
    "correct = 0\n",
    "total = 0\n",
    "test_predicts = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      outputs = model(images)\n",
    "      _, predicts = torch.max(outputs, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicts == labels).sum().item()\n",
    "      test_predicts.extend(predicts.cpu().numpy())\n",
    "      test_labels.extend(labels.cpu().numpy())\n",
    "print('Test Accuracy: {:.2f}%'.format(100 * correct / total))\n",
    "# plot the outputs\n",
    "sns.heatmap(confusion_matrix(test_labels,test_predicts), annot=True, fmt='d', cmap='Pastel1',vmin=0, vmax=7)\n",
    "plt.xlabel('Test Predicts')\n",
    "plt.ylabel('Test Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1698664472665,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "JRdCiaLhTXDR",
    "outputId": "d05b3f65-3659-42e3-8d6e-5457e70358f7"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_predicts)\n",
    "\n",
    "# precision, recall\n",
    "precision = precision_score(test_labels, test_predicts, average=None)\n",
    "recall = recall_score(test_labels, test_predicts, average=None)\n",
    "\n",
    "# specificity\n",
    "specificity = np.zeros_like(precision)\n",
    "for i in range(len(specificity)):\n",
    "    true_negative = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]\n",
    "    false_positive = np.sum(cm[:, i]) - cm[i, i]\n",
    "    specificity[i] = true_negative / (true_negative + false_positive)\n",
    "\n",
    "# show results\n",
    "for i in range(len(precision)):\n",
    "    print(\"Class {}: Precision: {:.2f}, Recall: {:.2f}, Specificity: {:.2f}\".format(i, precision[i], recall[i], specificity[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHaCBSXlUQdX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRpBKIcVF4vh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698739232220,
     "user_tz": -660,
     "elapsed": 11262,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     }
    },
    "outputId": "d23d8932-08a9-4306-9d6b-6b79ab2d1eee"
   },
   "outputs": [],
   "source": [
    "!pip install grad-cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 1188,
     "status": "ok",
     "timestamp": 1698739234894,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "P789z_dcK5Xi",
    "outputId": "a2e41464-24ad-413c-ab85-88e3f93d5375"
   },
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# last layer\n",
    "target_layers = [model.resnet.layer4[-1]]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "image = Image.open(\"/content/drive/MyDrive/comp8420/Subset For Assignment SFEW/Happy/Bridesmaids_000059880_00000039.png\")\n",
    "input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# create cam\n",
    "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=device=='cuda')\n",
    "\n",
    "targets = [ClassifierOutputTarget(0)]\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "visualization = show_cam_on_image(input_tensor.cpu().numpy()[0].transpose(1, 2, 0), grayscale_cam, use_rgb=True)\n",
    "\n",
    "plt.imshow(visualization)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVyLFi82HVpE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "executionInfo": {
     "elapsed": 1447,
     "status": "ok",
     "timestamp": 1698651136010,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "93lD1rwW9ang",
    "outputId": "5594dc7c-d15b-48ae-b130-50bcc3dc1cf7"
   },
   "outputs": [],
   "source": [
    "kernels = model.resnet.conv1.weight.data.cpu().numpy()\n",
    "kernels = kernels.transpose(0, 2, 3, 1)\n",
    "kernels = (kernels - kernels.min()) / (kernels.max() - kernels.min())\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(8, 8))\n",
    "for i in range(64):\n",
    "    row = i // 8\n",
    "    col = i % 8\n",
    "    axs[row, col].imshow(kernels[i, :, :, :], cmap='viridis')\n",
    "    axs[row, col].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1698657972071,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "ROFhF22lAViv",
    "outputId": "e1cf632a-9f1f-4ec8-8604-d870477128e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(val_labels, val_predicts)\n",
    "print(report)\n",
    "\n",
    "report = classification_report(test_labels, test_predicts)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1698458865516,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "jKyS0VbgBV7N",
    "outputId": "762c9686-28e6-40ec-aaa7-b9f290440098"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "executionInfo": {
     "elapsed": 4728,
     "status": "ok",
     "timestamp": 1698458999433,
     "user": {
      "displayName": "Mengfan Yan",
      "userId": "02419155310702662578"
     },
     "user_tz": -660
    },
    "id": "IxIyNtEpBlln",
    "outputId": "6e4025e9-1825-4394-c6e3-d587e9c25b15"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=/content/drive/MyDrive/comp8420/runs --port=6007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8GvwQaCB4MN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "mount_file_id": "1gmNhEPqWOXym1l1IVfVq4NRYnqklRAjl",
   "authorship_tag": "ABX9TyMqm6joaFM5P4Zx4FE/hehE"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
